#!/bin/bash
#SBATCH --job-name=my_array_job
#SBATCH --output=output_%A_%a.out
#SBATCH --error=error_%A_%a.err
#SBATCH --array=0-1295  # Define the range of array indices
#SBATCH --time=00:30:00  # 30 minutes per job
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem=1G

#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=federica.sibilla@unil.ch

# Load necessary modules (if any)
module load gcc python

# Activate the Python virtual environment
source myenv/bin/activate

# Define arrays of parameters
n_resources_arr=(5 8 17 25)
supplied_arr=(1 2 3)
average_consumed_arr=(1 3 4)
leakage_arr=(0.2 0.8)
repl_arr=(100 1000)
sparsity_arr=(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9) 

# Get the index from SLURM_ARRAY_TASK_ID
index=${SLURM_ARRAY_TASK_ID}

# Calculate the number of combinations per parameter array
n_resources_count=${#n_resources_arr[@]}
supplied_count=${#supplied_arr[@]}
average_consumed_count=${#average_consumed_arr[@]}
leakage_count=${#leakage_arr[@]}
repl_count=${#repl_arr[@]}
sparsity_count=${#sparsity_arr[@]}

# Determine the current combination parameters

# Total number of combinations (adding sparsity_count)
total_combinations=$((n_resources_count * supplied_count * average_consumed_count * leakage_count * repl_count * sparsity_count))

# Ensure the index is within bounds
if [ $index -ge $total_combinations ]; then
  echo "Error: SLURM_ARRAY_TASK_ID exceeds total combinations!"
  exit 1
fi

# Determine the current combination parameters
combination_index=$((index % total_combinations))
n_resources_index=$((combination_index / (supplied_count * average_consumed_count * leakage_count * repl_count * sparsity_count)))
combination_index=$((combination_index % (supplied_count * average_consumed_count * leakage_count * repl_count * sparsity_count)))
supplied_index=$((combination_index / (average_consumed_count * leakage_count * repl_count * sparsity_count)))
combination_index=$((combination_index % (average_consumed_count * leakage_count * repl_count * sparsity_count)))
average_consumed_index=$((combination_index / (leakage_count * repl_count * sparsity_count)))
combination_index=$((combination_index % (leakage_count * repl_count * sparsity_count)))
leakage_index=$((combination_index / (repl_count * sparsity_count)))
combination_index=$((combination_index % (repl_count * sparsity_count)))
repl_index=$((combination_index / sparsity_count))
sparsity_index=$((combination_index % sparsity_count))

# Extract parameter values
n_resources=${n_resources_arr[$n_resources_index]}
supplied=${supplied_arr[$supplied_index]}
average_consumed=${average_consumed_arr[$average_consumed_index]}
leakage=${leakage_arr[$leakage_index]}
repl=${repl_arr[$repl_index]}
sparsity=${sparsity_arr[$sparsity_index]}

# Esegui lo script Python con i parametri scelti
python /users/fsibilla/CR_to_LV_generate/CR_generation.py $n_resources $supplied $average_consumed $leakage $repl $sparsity